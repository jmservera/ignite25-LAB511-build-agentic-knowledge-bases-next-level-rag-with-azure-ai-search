{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0a1e1d",
   "metadata": {},
   "source": [
    "# Part 7: Minimal Knowledge Base\n",
    "\n",
    "In Parts 1-6, you used knowledge bases with full agentic reasoning capabilities. Part 7 dives into the **minimal reasoning effort** optimization, which trades some reasoning sophistication for significant improvements in speed and cost. This approach is ideal when you need fast, cost-effective retrieval for simpler queries.\n",
    "\n",
    "## Step 1: Load Environment Variables\n",
    "\n",
    "Run below cell to load the configuration for your Azure resources, choose the **.venv(3.12.1)** environment that is created for you. \n",
    "\n",
    "This time you'll create a knowledge base optimized for minimal reasoning effort.\n",
    "\n",
    "> **⚠️ Troubleshooting**\n",
    ">\n",
    "> If code cells get stuck and keep spinning, select **Restart** from the notebook toolbar at the top. If the issue persists after a couple of tries, close VS Code completely and reopen it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88564a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Azure AI Search configuration\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Knowledge base name\n",
    "knowledge_base_name = \"minimal-knowledge-base\"\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_chatgpt_deployment = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"gpt-4.1\")\n",
    "azure_openai_chatgpt_model_name = os.getenv(\"AZURE_OPENAI_CHATGPT_MODEL_NAME\", \"gpt-4.1\")\n",
    "\n",
    "print(\"Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b649102",
   "metadata": {},
   "source": [
    "## Step 2: Create Minimal Reasoning Knowledge Base\n",
    "\n",
    "Let's create a knowledge base optimized for speed and cost using `KnowledgeRetrievalMinimalReasoningEffort`. \n",
    "\n",
    "Notice two key differences from previous parts:\n",
    "\n",
    "1. **No Azure OpenAI model configuration**: The knowledge base skips LLM-powered query planning and answer synthesis\n",
    "2. **`EXTRACTIVE_DATA` output mode**: Returns raw chunks instead of synthesized answers\n",
    "\n",
    "This configuration prioritizes speed and cost savings over sophisticated reasoning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeRetrievalMinimalReasoningEffort, KnowledgeRetrievalOutputMode, KnowledgeSourceReference\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=knowledge_base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(name=\"healthdocs-knowledge-source\"),\n",
    "        KnowledgeSourceReference(name=\"hrdocs-knowledge-source\"),\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "\n",
    "index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "print(f\"Knowledge base '{knowledge_base_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f194ea5",
   "metadata": {},
   "source": [
    "## Step 3: Query with Semantic Intents\n",
    "\n",
    "Minimal reasoning knowledge bases use `KnowledgeRetrievalSemanticIntent` instead of conversational messages. Each intent executes as a direct search query against your knowledge sources.\n",
    "\n",
    "The code below runs two semantic intents and returns a result that contains references and activity log, but no synthesized answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import KnowledgeBaseRetrievalRequest, KnowledgeRetrievalSemanticIntent, SearchIndexKnowledgeSourceParams\n",
    "\n",
    "knowledge_base_client = KnowledgeBaseRetrievalClient(endpoint=endpoint, knowledge_base_name=knowledge_base_name, credential=credential)\n",
    "healthdocs_ks_params = SearchIndexKnowledgeSourceParams(\n",
    "    knowledge_source_name=\"healthdocs-knowledge-source\",\n",
    "    include_references=True,\n",
    "    include_reference_source_data=True,\n",
    ")\n",
    "hrdocs_ks_params = SearchIndexKnowledgeSourceParams(\n",
    "    knowledge_source_name=\"hrdocs-knowledge-source\",\n",
    "    include_references=True,\n",
    "    include_reference_source_data=True,\n",
    ")\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    intents=[\n",
    "        KnowledgeRetrievalSemanticIntent(\n",
    "            search=\"What is the responsibility of the Zava CEO?\"\n",
    "        ),\n",
    "        KnowledgeRetrievalSemanticIntent(\n",
    "            search=\"What Zava health plan would you recommend if they wanted the best coverage for mental health services?\"\n",
    "        )\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        healthdocs_ks_params,\n",
    "        hrdocs_ks_params\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "result = knowledge_base_client.retrieve(retrieval_request=req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b58cc1",
   "metadata": {},
   "source": [
    "## Step 4: Review Raw Retrieved Data\n",
    "\n",
    "The results from the minimal reasoning knowledge base will include raw data chunks retrieved from your knowledge sources. A base with minimal effort is helpful when you are integrating agentic retrieval into an application that has its own LLM question-answering logic or if you are surfacing the results directly.\n",
    "\n",
    "Run the code and observe the results to see how minimal reasoning knowledge bases can efficiently handle your queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae82fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "references = json.dumps([ref.as_dict() for ref in result.references], indent=2)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "activity_types = [{\"type\": a.type} for a in result.activity]\n",
    "\n",
    "df = pd.DataFrame(activity_types)\n",
    "\n",
    "print(\"Activity Log Steps\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
    "print(\"Activity Details\")\n",
    "print(activity_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e37ac2",
   "metadata": {},
   "source": [
    "## Step 5: Generate Synthesized Answer\n",
    "\n",
    "If you want a synthesized answer from the retrieved chunks, you can pass them to an LLM for processing. The code below demonstrates how to generate a concise answer using the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "openai_client = AsyncOpenAI(\n",
    "    base_url=azure_openai_endpoint + \"openai/v1/\"\n",
    ")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    model=azure_openai_chatgpt_deployment,\n",
    "    instructions=\"You are a helpful assistant that provides concise answers based on the provided context.\",\n",
    "    input=f\"\"\"\n",
    "    Based on the following context, answer the question concisely.\\n\\nContext:\\n{result.response[0].content[0].text}\n",
    "    \\n\\nQuestion:\\nWhat is the responsibility of the Zava CEO?\n",
    "    What Zava health plan would you recommend if they wanted the best coverage for mental health services?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279c41c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've now experienced minimal reasoning knowledge bases optimized for speed and cost over sophisticated reasoning capabilities.\n",
    "\n",
    "**Key concepts to remember:**\n",
    "- `KnowledgeRetrievalMinimalReasoningEffort` prioritizes speed and cost savings over advanced reasoning\n",
    "- `EXTRACTIVE_DATA` output mode returns raw chunks instead of synthesized answers\n",
    "- `KnowledgeRetrievalSemanticIntent` structures queries as focused search intents rather than conversational messages\n",
    "- No Azure OpenAI model required in the knowledge base configuration, reducing baseline costs\n",
    "- Optional post-processing with Azure OpenAI gives you control over when to use LLM synthesis\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "➡️ Continue to [Part 8: Medium Knowledge Base](part8-medium-knowledge-base.ipynb) to learn how medium reasoning effort balances sophistication with performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
