{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a2030865",
            "metadata": {},
            "source": [
                "# Part 5: Blob Knowledge Source\n",
                "\n",
                "In Parts 1-4, you worked with pre-indexed data, SharePoint, and web sources. In Part 5, you'll upload documents from Azure Blob Storage and create knowledge sources that index them automatically. You'll also compare two indexing modes: **minimal** (basic content extraction) and **standard** (advanced content understanding with Azure AI Services).\n",
                "\n",
                "## Step 1: Load Environment Variables\n",
                "\n",
                "Run below cell to load the configuration for your Azure resources, choose the **.venv** environment that is created for you.\n",
                "\n",
                "Notice the additional variables for blob storage, AI services, and embedding models, which are needed for document ingestion and vectorization. All these Azure resources are pre-configured in `.env` for you.\n",
                "\n",
                "> **⚠️ Troubleshooting**\n",
                ">\n",
                "> If code cells get stuck and keep spinning, select **Restart** from the notebook toolbar at the top. If the issue persists after a couple of tries, close VS Code completely and reopen it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9a4c30fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "from azure.core.credentials import AzureKeyCredential\n",
                "from azure.identity import DefaultAzureCredential\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(override=True) # take environment variables from .env.\n",
                "\n",
                "# Azure AI Search configuration\n",
                "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
                "if os.getenv('KEYLESS','false').lower() == 'true':\n",
                "    credential = DefaultAzureCredential()    \n",
                "else:\n",
                "    credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"])\n",
                "\n",
                "# Knowledge base name\n",
                "knowledge_base_name = \"upload-blob-knowledge-base-minimal\"\n",
                "standard_knowledge_base_name = \"upload-blob-knowledge-base-standard\"\n",
                "\n",
                "# Azure OpenAI configuration\n",
                "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
                "if os.getenv('KEYLESS','false').lower() == 'true':\n",
                "    azure_openai_key = ''\n",
                "else:\n",
                "    azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
                "azure_openai_chatgpt_deployment = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"gpt-4.1\")\n",
                "azure_openai_chatgpt_model_name = os.getenv(\"AZURE_OPENAI_CHATGPT_MODEL_NAME\", \"gpt-4.1\")\n",
                "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
                "azure_openai_embedding_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\", \"text-embedding-3-large\")\n",
                "\n",
                "# Blob configuration\n",
                "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
                "blob_resource_id = os.environ[\"BLOB_RESOURCE_ID\"]\n",
                "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
                "ai_services_endpoint = os.environ[\"AI_SERVICES_ENDPOINT\"]\n",
                "\n",
                "blob_path = \"../data/ai-search-data/blobdata/MSFT_cloud_architecture_zava.pdf\"\n",
                "\n",
                "print(\"Environment variables loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d6a57dec",
            "metadata": {},
            "source": [
                "## Step 2: Upload Document to Blob Storage\n",
                "\n",
                "Before creating a knowledge source, you need to upload a document to your blob storage. The code below uploads a PDF called `MSFT_cloud_architecture_zava.pdf` which contains information about Zava's cloud architecture and how they classify data by sensitivity level.\n",
                "\n",
                "Once you create the blob knowledge source in the next step, it will automatically find this PDF in the storage and index it for querying."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61b5472f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.storage.blob import BlobServiceClient\n",
                "\n",
                "if os.getenv('KEYLESS','false').lower() == 'true':\n",
                "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=blob_connection_string,credential=credential)\n",
                "else:\n",
                "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=blob_connection_string)\n",
                "container_client = blob_service_client.get_container_client(blob_container_name)\n",
                "blob_name = os.path.basename(blob_path)\n",
                "blob_client = container_client.get_blob_client(blob_name)\n",
                "if not blob_client.exists():\n",
                "    with open(blob_path, \"rb\") as data:\n",
                "        blob_client.upload_blob(data, overwrite=True)\n",
                "\n",
                "print(f\"Setup sample data in {blob_container_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7a7d4627",
            "metadata": {},
            "source": [
                "## Step 3: Create Blob Knowledge Source with Minimal Extraction\n",
                "\n",
                "An **AzureBlobKnowledgeSource** automatically indexes documents from blob storage. Unlike the sources you've used before, this one ingests and processes the documents for you.\n",
                "\n",
                "The code below creates a knowledge source with a `content_extraction_mode` of **minimal**. This mode chunks documents quickly without deep semantic understanding. An embedding model (`text-embedding-3-large`) is used to vectorize the chunks for vector search, but the chunking strategy itself is basic and fast.\n",
                "\n",
                ">Minimal indexing is ideal when you need speed and have straightforward documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "250a8079",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.search.documents.indexes import SearchIndexClient\n",
                "from azure.search.documents.indexes.models import AzureBlobKnowledgeSource, AzureBlobKnowledgeSourceParameters, AzureOpenAIVectorizerParameters, KnowledgeSourceAzureOpenAIVectorizer, KnowledgeSourceContentExtractionMode, KnowledgeSourceIngestionParameters\n",
                "\n",
                "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
                "\n",
                "embedding_model = KnowledgeSourceAzureOpenAIVectorizer(\n",
                "    azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
                "        resource_url=azure_openai_endpoint,\n",
                "        api_key=azure_openai_key,\n",
                "        deployment_name=azure_openai_embedding_deployment,\n",
                "        model_name=azure_openai_embedding_model_name\n",
                "    )\n",
                ")\n",
                "\n",
                "# Uses ResourceId-based connection string for managed identity authentication\n",
                "# The Azure AI Search service needs \"Storage Blob Data Reader\" role on the storage account\n",
                "# See https://aka.ms/azure-search-blob-datasource-authorization for more details.\n",
                "\n",
                "\n",
                "if not blob_resource_id:\n",
                "    print(\"Using connection string with account key for authentication.\")\n",
                "    connection_string=blob_connection_string\n",
                "else:\n",
                "    print(\"Using ResourceId-based connection string for authentication. Make sure the Azure AI Search service has 'Storage Blob Data Reader' role on the storage account.\")\n",
                "    connection_string=f\"ResourceId={blob_resource_id}\"\n",
                "\n",
                "knowledge_source = AzureBlobKnowledgeSource(\n",
                "    name=\"upload-blob-knowledge-source-minimal\",\n",
                "    azure_blob_parameters=AzureBlobKnowledgeSourceParameters(\n",
                "        connection_string=connection_string,\n",
                "        container_name=blob_container_name,\n",
                "        ingestion_parameters=KnowledgeSourceIngestionParameters(\n",
                "            embedding_model=embedding_model,\n",
                "            content_extraction_mode=KnowledgeSourceContentExtractionMode.MINIMAL\n",
                "        ),\n",
                "    )\n",
                ")\n",
                "\n",
                "index_client.create_or_update_knowledge_source(knowledge_source=knowledge_source)\n",
                "print(f\"Knowledge source '{knowledge_source.name}' created or updated successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f3331023",
            "metadata": {},
            "source": [
                "## Step 4: Check Knowledge Source Status\n",
                "\n",
                "After creating a blob knowledge source, it needs time to process the documents. The code below checks whether indexing is complete, in progress, or failed.\n",
                "\n",
                "Once you see that `itemsUpdatesProcessed` is 1, that means the single document has been indexed successfully. Once indexing is complete, you can move to the next step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fcc47525",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "status = index_client.get_knowledge_source_status(knowledge_source.name)\n",
                "\n",
                "print(json.dumps(status.serialize(), indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f744c762",
            "metadata": {},
            "source": [
                "## Step 5: Create Knowledge Base\n",
                "\n",
                "Now that the blob knowledge source has indexed the document, you can create a knowledge base to query it. The code below creates a knowledge base that uses the blob knowledge source you created earlier.\n",
                "\n",
                "Notice that this knowledge base also set `retrieval_reasoning_effort` to \"low\". Currently, the lowest possible effort is \"minimal\" and highest possible is \"medium\". The \"low\" effort will still perform query decomposition, but it will not do iterative retrieval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "869eec9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.search.documents.indexes.models import AzureOpenAIVectorizerParameters, KnowledgeBase, KnowledgeBaseAzureOpenAIModel, KnowledgeRetrievalLowReasoningEffort, KnowledgeRetrievalOutputMode, KnowledgeSourceReference\n",
                "\n",
                "aoai_params = AzureOpenAIVectorizerParameters(\n",
                "    resource_url=azure_openai_endpoint,\n",
                "    api_key=azure_openai_key,\n",
                "    deployment_name=azure_openai_chatgpt_deployment,\n",
                "    model_name=azure_openai_chatgpt_model_name,\n",
                ")\n",
                "\n",
                "knowledge_base = KnowledgeBase(\n",
                "    name=knowledge_base_name,\n",
                "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
                "    knowledge_sources=[\n",
                "        KnowledgeSourceReference(name=knowledge_source.name)\n",
                "    ],\n",
                "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
                "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
                ")\n",
                "\n",
                "index_client.create_or_update_knowledge_base(knowledge_base)\n",
                "print(f\"Knowledge base '{knowledge_base_name}' created or updated successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e7c50f9",
            "metadata": {},
            "source": [
                "## Step 6: Use agentic retrieval to fetch results from Blob Knowledge Source\n",
                "\n",
                "The code below queries the PDF document about Zava's data sensitivity classification levels. This demonstrates how agentic retrieval works with blob knowledge sources.\n",
                "\n",
                "When you run this query, the knowledge base analyzes your question, decomposes it into focused subqueries, searches the blob-indexed content concurrently, uses semantic ranking to filter results, and synthesizes a grounded answer with citations pointing back to the PDF document."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5775dd44",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
                "from azure.search.documents.knowledgebases.models import AzureBlobKnowledgeSourceParams, KnowledgeBaseMessage, KnowledgeBaseMessageTextContent, KnowledgeBaseRetrievalRequest\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "knowledge_base_client = KnowledgeBaseRetrievalClient(endpoint=endpoint, knowledge_base_name=knowledge_base_name, credential=credential)\n",
                "\n",
                "blob_ks_params = AzureBlobKnowledgeSourceParams(\n",
                "    knowledge_source_name=knowledge_source.name,\n",
                "    include_references=True,\n",
                "    include_reference_source_data=True\n",
                ")\n",
                "req = KnowledgeBaseRetrievalRequest(\n",
                "    messages=[\n",
                "        KnowledgeBaseMessage(role=\"user\", content=[KnowledgeBaseMessageTextContent(text=\"What are the levels of Zava data sensitivity classification?\")])\n",
                "    ],\n",
                "    knowledge_source_params=[\n",
                "        blob_ks_params\n",
                "    ],\n",
                "    include_activity=True\n",
                ")\n",
                "\n",
                "\n",
                "result = knowledge_base_client.retrieve(retrieval_request=req)\n",
                "display(Markdown(result.response[0].content[0].text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75661dee",
            "metadata": {},
            "source": [
                "## Step 7: Review Response, References, and Activity\n",
                "\n",
                "The two cells below show the citations and activity log from the blob knowledge source query.\n",
                "\n",
                "The references reveal which chunks from the PDF were used to answer your question. \n",
                "\n",
                "The activity log shows how the knowledge base processed your query and retrieved information from the blob-indexed content."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "300eb48b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "references = json.dumps([ref.as_dict() for ref in result.references], indent=2)\n",
                "print(references)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5fbb6a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "activity_types = [{\"type\": a.type} for a in result.activity]\n",
                "\n",
                "df = pd.DataFrame(activity_types)\n",
                "\n",
                "print(\"Activity Log Steps\")\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ca66d5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
                "print(\"Activity Details\")\n",
                "print(activity_content)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac380c8d",
            "metadata": {},
            "source": [
                "## Step 8: Use Standard extraction mode with Content Understanding\n",
                "\n",
                "In the previous steps, you created a blob knowledge source with minimal extraction mode. Now, you'll create another blob knowledge source using the **standard** extraction mode, which leverages Azure AI Services for deeper content understanding. This mode provides advanced chunking strategies, semantic extraction, and better handling of complex documents.\n",
                "\n",
                "The code below adds `content_extraction_mode=STANDARD` and connects Azure AI Services for enhanced processing. \n",
                "\n",
                ">Standard extraction takes longer but produces higher-quality chunks that preserve document structure and relationships."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22490f28",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from azure.search.documents.indexes.models import AIServices, KnowledgeSourceContentExtractionMode\n",
                "\n",
                "standard_knowledge_source = AzureBlobKnowledgeSource(\n",
                "    name=\"upload-blob-knowledge-source-standard\",\n",
                "    azure_blob_parameters=AzureBlobKnowledgeSourceParameters(\n",
                "        connection_string=connection_string,\n",
                "        container_name=blob_container_name,\n",
                "        ingestion_parameters=KnowledgeSourceIngestionParameters(\n",
                "            embedding_model=embedding_model,\n",
                "            ai_services=AIServices(uri=ai_services_endpoint),\n",
                "            content_extraction_mode=KnowledgeSourceContentExtractionMode.STANDARD\n",
                "        )\n",
                "    )\n",
                ")\n",
                "\n",
                "index_client.create_or_update_knowledge_source(knowledge_source=standard_knowledge_source)\n",
                "print(f\"Knowledge source '{standard_knowledge_source.name}' created or updated successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad3fe3c1",
            "metadata": {},
            "source": [
                "## Step 9: Check Standard Extraction Status\n",
                "\n",
                "Run below cell to monitor the standard extraction progress. This mode uses Azure AI Services to analyze document structure, recognize tables, and perform intelligent chunking, which takes more time than the minimal extraction mode we used earlier.\n",
                "\n",
                "Once you see that `itemsUpdatesProcessed` is 1, that means the single document has been indexed successfully. Once indexing is complete, you can move to the next step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aded544b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "status = index_client.get_knowledge_source_status(standard_knowledge_source.name)\n",
                "\n",
                "print(json.dumps(status.serialize(), indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "434cf9c0",
            "metadata": {},
            "source": [
                "## Step 10: Create Knowledge Base for Standard Extraction\n",
                "\n",
                "You'll now create a knowledge base that uses the standard extraction blob knowledge source. This knowledge base will benefit from the enhanced document processing and improved chunk quality.\n",
                "\n",
                "Run below cell to create the knowledge base with the standard extraction source."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f3f4931",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeBaseAzureOpenAIModel, KnowledgeRetrievalOutputMode, KnowledgeSourceReference\n",
                "\n",
                "standard_knowledge_base = KnowledgeBase(\n",
                "    name=standard_knowledge_base_name,\n",
                "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
                "    knowledge_sources=[\n",
                "        KnowledgeSourceReference(name=standard_knowledge_source.name)\n",
                "    ],\n",
                "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS\n",
                ")\n",
                "\n",
                "index_client.create_or_update_knowledge_base(standard_knowledge_base)\n",
                "print(f\"Knowledge base '{standard_knowledge_base_name}' created or updated successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "86d5d170",
            "metadata": {},
            "source": [
                "## Step 11: Query Standard Extraction Knowledge Base\n",
                "\n",
                "Run the same query about Zava's data sensitivity classification levels, but this time against the standard extraction knowledge base. \n",
                "\n",
                "Compare this response with the one from Step 6. You may notice differences in answer quality, completeness, or organization due to the improved document processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "438e7eac",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
                "from azure.search.documents.knowledgebases.models import AzureBlobKnowledgeSourceParams, KnowledgeBaseMessage, KnowledgeBaseMessageTextContent, KnowledgeBaseRetrievalRequest\n",
                "\n",
                "standard_knowledge_base_client = KnowledgeBaseRetrievalClient(endpoint=endpoint, knowledge_base_name=standard_knowledge_base_name, credential=credential)\n",
                "\n",
                "blob_ks_params = AzureBlobKnowledgeSourceParams(\n",
                "    knowledge_source_name=standard_knowledge_source.name,\n",
                "    include_references=True,\n",
                "    include_reference_source_data=True\n",
                ")\n",
                "req = KnowledgeBaseRetrievalRequest(\n",
                "    messages=[\n",
                "        KnowledgeBaseMessage(role=\"user\", content=[KnowledgeBaseMessageTextContent(text=\"What are the levels of Zava data sensitivity classification?\")])\n",
                "    ],\n",
                "    knowledge_source_params=[\n",
                "        blob_ks_params\n",
                "    ],\n",
                "    include_activity=True\n",
                ")\n",
                "\n",
                "\n",
                "result = standard_knowledge_base_client.retrieve(retrieval_request=req)\n",
                "display(Markdown(result.response[0].content[0].text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b359f628",
            "metadata": {},
            "source": [
                "## Step 12: Compare Extraction Results\n",
                "\n",
                "The cell below shows citations from the standard extraction query.\n",
                "\n",
                "Compare these references with those from Step 7 to see how different extraction modes affect chunk creation and information retrieval from the same PDF document."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5569d6c1",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "references = json.dumps([ref.as_dict() for ref in result.references], indent=2)\n",
                "print(references)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3c3b3b56",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "You've now experienced blob knowledge sources and compared different content extraction modes for document processing.\n",
                "\n",
                "**Key concepts to remember:**\n",
                "- `AzureBlobKnowledgeSource` automatically indexes documents from Azure Blob Storage\n",
                "- **Minimal extraction**: Fast, basic text extraction suitable for simple documents\n",
                "- **Standard extraction**: Uses Azure AI Services for advanced document understanding and better chunk quality\n",
                "- Standard extraction is beneficial for complex documents with tables, images, or intricate layouts\n",
                "- Both modes create searchable, vectorized chunks from your blob documents\n",
                "\n",
                "### What's Next?\n",
                "\n",
                "➡️ Continue to [Part 6: Combined Knowledge Sources](part6-combined-knowledge-source.ipynb) to learn how to query search indexes, web URLs, SharePoint, and blob storage simultaneously in a single knowledge base."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
